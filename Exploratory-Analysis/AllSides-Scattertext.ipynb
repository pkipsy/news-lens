{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Scattertext to All Sides Headline Roundup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:98% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import modules\n",
    "%matplotlib inline\n",
    "import scattertext as st\n",
    "import re, io\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import rankdata, hmean, norm\n",
    "import spacy\n",
    "import os, pkgutil, json, urllib\n",
    "from urllib.request import urlopen\n",
    "from IPython.display import IFrame\n",
    "from IPython.core.display import display, HTML\n",
    "from scattertext import CorpusFromPandas, produce_scattertext_explorer\n",
    "display(HTML(\"<style>.container { width:98% !important; }</style>\"))\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grab the All Sides media set and preview it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>main_headline</th>\n",
       "      <th>description</th>\n",
       "      <th>source</th>\n",
       "      <th>bias</th>\n",
       "      <th>headline</th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "      <th>text_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2018-06-13</td>\n",
       "      <td>b'May Jobs Report Sparks Debate on Who Deserve...</td>\n",
       "      <td>With the recent release of the May jobs report...</td>\n",
       "      <td>Washington Post</td>\n",
       "      <td>Left</td>\n",
       "      <td>b'How trend-riding Trump is taking credit for ...</td>\n",
       "      <td>https://www.washingtonpost.com/news/posteveryt...</td>\n",
       "      <td>Jared Bernstein, a former chief economist to V...</td>\n",
       "      <td>5870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-06-13</td>\n",
       "      <td>b'May Jobs Report Sparks Debate on Who Deserve...</td>\n",
       "      <td>With the recent release of the May jobs report...</td>\n",
       "      <td>Wall Street Journal- Editorial</td>\n",
       "      <td>Right</td>\n",
       "      <td>b'It\\xe2\\x80\\x99s Trump\\xe2\\x80\\x99s Economy Now'</td>\n",
       "      <td>https://www.wsj.com/articles/its-trumps-econom...</td>\n",
       "      <td>Liberals have opposed virtually every move Pre...</td>\n",
       "      <td>536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-06-13</td>\n",
       "      <td>b'May Jobs Report Sparks Debate on Who Deserve...</td>\n",
       "      <td>With the recent release of the May jobs report...</td>\n",
       "      <td>USA TODAY</td>\n",
       "      <td>Center</td>\n",
       "      <td>b'The Bubble: By undoing Obama accomplishments...</td>\n",
       "      <td>https://www.usatoday.com/story/news/politics/o...</td>\n",
       "      <td>CLOSE President Trump’s once bitter political ...</td>\n",
       "      <td>7123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2018-06-13</td>\n",
       "      <td>b'Michael Cohen Expected to Cooperate With Fed...</td>\n",
       "      <td>Attorneys for Michael Cohen, President Trump's...</td>\n",
       "      <td>Wall Street Journal- News</td>\n",
       "      <td>Center</td>\n",
       "      <td>b'Trump Lawyer Michael Cohen\\xe2\\x80\\x99s Atto...</td>\n",
       "      <td>https://www.wsj.com/articles/trump-lawyer-mich...</td>\n",
       "      <td>The attorneys for Michael Cohen, President Don...</td>\n",
       "      <td>538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2018-06-13</td>\n",
       "      <td>b'Michael Cohen Expected to Cooperate With Fed...</td>\n",
       "      <td>Attorneys for Michael Cohen, President Trump's...</td>\n",
       "      <td>Vox</td>\n",
       "      <td>Left</td>\n",
       "      <td>b'Reports suggest Michael Cohen is thinking of...</td>\n",
       "      <td>https://www.vox.com/2018/6/13/17458594/michael...</td>\n",
       "      <td>Longtime Trump lawyer Michael Cohen is changin...</td>\n",
       "      <td>6986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        date                                      main_headline  \\\n",
       "0           0  2018-06-13  b'May Jobs Report Sparks Debate on Who Deserve...   \n",
       "1           1  2018-06-13  b'May Jobs Report Sparks Debate on Who Deserve...   \n",
       "2           2  2018-06-13  b'May Jobs Report Sparks Debate on Who Deserve...   \n",
       "3           4  2018-06-13  b'Michael Cohen Expected to Cooperate With Fed...   \n",
       "4           5  2018-06-13  b'Michael Cohen Expected to Cooperate With Fed...   \n",
       "\n",
       "                                         description  \\\n",
       "0  With the recent release of the May jobs report...   \n",
       "1  With the recent release of the May jobs report...   \n",
       "2  With the recent release of the May jobs report...   \n",
       "3  Attorneys for Michael Cohen, President Trump's...   \n",
       "4  Attorneys for Michael Cohen, President Trump's...   \n",
       "\n",
       "                           source     bias  \\\n",
       "0                 Washington Post    Left    \n",
       "1  Wall Street Journal- Editorial   Right    \n",
       "2                       USA TODAY  Center    \n",
       "3       Wall Street Journal- News  Center    \n",
       "4                             Vox    Left    \n",
       "\n",
       "                                            headline  \\\n",
       "0  b'How trend-riding Trump is taking credit for ...   \n",
       "1  b'It\\xe2\\x80\\x99s Trump\\xe2\\x80\\x99s Economy Now'   \n",
       "2  b'The Bubble: By undoing Obama accomplishments...   \n",
       "3  b'Trump Lawyer Michael Cohen\\xe2\\x80\\x99s Atto...   \n",
       "4  b'Reports suggest Michael Cohen is thinking of...   \n",
       "\n",
       "                                                link  \\\n",
       "0  https://www.washingtonpost.com/news/posteveryt...   \n",
       "1  https://www.wsj.com/articles/its-trumps-econom...   \n",
       "2  https://www.usatoday.com/story/news/politics/o...   \n",
       "3  https://www.wsj.com/articles/trump-lawyer-mich...   \n",
       "4  https://www.vox.com/2018/6/13/17458594/michael...   \n",
       "\n",
       "                                                text  text_len  \n",
       "0  Jared Bernstein, a former chief economist to V...      5870  \n",
       "1  Liberals have opposed virtually every move Pre...       536  \n",
       "2  CLOSE President Trump’s once bitter political ...      7123  \n",
       "3  The attorneys for Michael Cohen, President Don...       538  \n",
       "4  Longtime Trump lawyer Michael Cohen is changin...      6986  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convention_df = pd.read_csv(\"/Users/meldye/Documents/Insight/news-corpus-df.csv\")\n",
    "convention_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Count\n",
      "bias\n",
      "Center      807\n",
      "Left       1316\n",
      "Right      1039\n",
      "Name: text, dtype: int64\n",
      "Word Count\n"
     ]
    }
   ],
   "source": [
    "print(\"Document Count\")\n",
    "print(convention_df.groupby('bias')['text'].count())\n",
    "print(\"Word Count\")\n",
    "convention_df.groupby('bias').apply(lambda x: x.text.apply(lambda x: len(x.split())).sum())\n",
    "convention_df['text'] = convention_df.text.apply(nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turn it into a Scattertext corpus and have spaCy parse it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = st.CorpusFromParsedDocuments(convention_df, category_col='bias', parsed_col='text').build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stop words\n",
    "stop_word_list = ['ad', '\\'s rise', 'photo wait', 'or blog', 'blog', 'skip', 'b.', 'read or', 'or share', 'device', 'unsupported', 'unsupported on', 'your device', 'enlarge', 'autoplay', 'embed', 'copy this', 'unsubscribe', 'toggle', 'playback', '76', 'of 76', 's.', '37', 'is', 'are', 'and the', 'is the', 'to get', 'also', 'however', 'n’t', 'also said', 'for a', '’ve', '10', '1', 'r', '#', '’ve', 'it ’s', 'n’t', 'that ’s', 'around', 'around the', 'that they', 'and his', 'of his', '’m', 'i ’m', 'something', 'caption', 'post', 'view', '/ the', '’s', '’re', 'videos', 'replay more', 'read more', 'watch', 'replay', 'must watch', 'just watched', 'more videos', 'hide caption', '―', 'photos', 'hide', 'watched', 'cnn', 'washington post', 'told cnn', 'washington times', 'times llc', '_', '© 2018', 'click here', '©', 'click', 'here for', 'reprint permission', 'for reprint', 'reprint', 'llc', 'press contributed', 'permission', 'told fox', 'the associated', 'associated press', 'associated', 'copyright', 'fox news', 'mrs.', 'ms.', 'mr.', 'this report', 'contributed to', 'fox', 'contributed', 'to this', 'copyright ©', 'said mr.', 'advertisement', '2018', 'the washington', 'times', '&', 'follow']\n",
    "stop_word_list = list(set(stop_word_list))\n",
    "corpus=corpus.remove_terms(stop_word_list)\n",
    "# corpus.get_stoplisted_unigram_corpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Left  freq</th>\n",
       "      <th>Right  freq</th>\n",
       "      <th>Center  freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>jared</th>\n",
       "      <td>77</td>\n",
       "      <td>29</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bernstein</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>25512</td>\n",
       "      <td>13923</td>\n",
       "      <td>12429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>former</th>\n",
       "      <td>1117</td>\n",
       "      <td>660</td>\n",
       "      <td>685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chief</th>\n",
       "      <td>430</td>\n",
       "      <td>267</td>\n",
       "      <td>282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Left  freq  Right  freq  Center  freq\n",
       "term                                            \n",
       "jared              77           29            39\n",
       "bernstein           5            3             9\n",
       "a               25512        13923         12429\n",
       "former           1117          660           685\n",
       "chief             430          267           282"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_freq_df = corpus.get_term_freq_df()\n",
    "term_freq_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Left  freq', 'Right  freq', 'Center  freq']"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_freq_df = corpus.get_term_freq_df()\n",
    "list(term_freq_df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['trump', 'obama', 'comey', 'obamacare', 'twitter', 'tweeted', 'hillary', 'clinton', 'republicans', 'gop']\n"
     ]
    }
   ],
   "source": [
    "print(list(corpus.get_scaled_f_scores_vs_background().index[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the us',\n",
      " 'convention',\n",
      " 'rise',\n",
      " 'clinton ’s',\n",
      " 'email',\n",
      " 'king',\n",
      " 'sign',\n",
      " 'the campaign',\n",
      " 'climate',\n",
      " 'is that',\n",
      " 'of trump',\n",
      " 'attacks',\n",
      " 'he had',\n",
      " 'he ’s',\n",
      " 'emails',\n",
      " 'us',\n",
      " 'clinton',\n",
      " 'the democratic',\n",
      " 'muslim',\n",
      " 'to have',\n",
      " 'his own',\n",
      " 'continued',\n",
      " '11',\n",
      " 'national convention',\n",
      " 'united states']\n"
     ]
    }
   ],
   "source": [
    "term_freq_df = corpus.get_term_freq_df()\n",
    "term_freq_df['Left Score'] = \\\n",
    "corpus.get_scaled_f_scores('Left ')\n",
    "pprint(list(term_freq_df.sort_values(by='Left Score', ascending=False).index[0:25]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mr. trump',\n",
      " 'mrs. clinton',\n",
      " 'illegal',\n",
      " 'president trump',\n",
      " 'the u.s.',\n",
      " 'press',\n",
      " 'israel',\n",
      " 'the media',\n",
      " 'here',\n",
      " 'free',\n",
      " 'obamacare',\n",
      " 'democrat',\n",
      " 'taxes',\n",
      " 'pence',\n",
      " 'we are',\n",
      " 'plan',\n",
      " 'we will',\n",
      " 'reports',\n",
      " 'the american',\n",
      " 'the obama',\n",
      " 'and we',\n",
      " 'plans',\n",
      " 'of our',\n",
      " 'american people',\n",
      " 'tweeted']\n"
     ]
    }
   ],
   "source": [
    "term_freq_df['Right Score'] = \\\n",
    "corpus.get_scaled_f_scores('Right ')\n",
    "pprint(list(term_freq_df.sort_values(by='Right Score', \n",
    "                                      ascending=False).index[0:25]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Left  freq</th>\n",
       "      <th>Right  freq</th>\n",
       "      <th>Center  freq</th>\n",
       "      <th>Left Score</th>\n",
       "      <th>Right Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>jared</th>\n",
       "      <td>77</td>\n",
       "      <td>29</td>\n",
       "      <td>39</td>\n",
       "      <td>0.720772</td>\n",
       "      <td>0.281460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bernstein</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0.457507</td>\n",
       "      <td>0.463126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>25512</td>\n",
       "      <td>13923</td>\n",
       "      <td>12429</td>\n",
       "      <td>0.912250</td>\n",
       "      <td>0.111604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>former</th>\n",
       "      <td>1117</td>\n",
       "      <td>660</td>\n",
       "      <td>685</td>\n",
       "      <td>0.124182</td>\n",
       "      <td>0.111371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chief</th>\n",
       "      <td>430</td>\n",
       "      <td>267</td>\n",
       "      <td>282</td>\n",
       "      <td>0.116896</td>\n",
       "      <td>0.114302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Left  freq  Right  freq  Center  freq  Left Score  Right Score\n",
       "term                                                                     \n",
       "jared              77           29            39    0.720772     0.281460\n",
       "bernstein           5            3             9    0.457507     0.463126\n",
       "a               25512        13923         12429    0.912250     0.111604\n",
       "former           1117          660           685    0.124182     0.111371\n",
       "chief             430          267           282    0.116896     0.114302"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_freq_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1200\"\n",
       "            height=\"700\"\n",
       "            src=\"output/AllSidesScattertextLog.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1b5f71fcf8>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = st.produce_scattertext_explorer(corpus,\n",
    "                                       category='Left ',\n",
    "                                       category_name='Left Leaning Media',\n",
    "                                       not_category_name='Right Leaning Media',\n",
    "                                       minimum_term_frequency=25,\n",
    "                                       width_in_pixels=1000,\n",
    "                                       transform=st.Scalers.log_scale_standardize)\n",
    "file_name = 'output/AllSidesScattertextLog.html'\n",
    "open(file_name, 'wb').write(html.encode('utf-8'))\n",
    "IFrame(src=file_name, width = 1200, height=700)\n",
    "\n",
    "html = produce_scattertext_explorer(corpus,\n",
    "                                    category='Left ',\n",
    "                                    category_name='Democratic',\n",
    "                                    not_category_name='Republican',\n",
    "                                    width_in_pixels=1000,\n",
    "                                    minimum_term_frequency=5,\n",
    "                                    metadata=convention_df['speaker'],\n",
    "                                    term_significance = st.LogOddsRatioUninformativeDirichletPrior())\n",
    "file_name = 'output/AllSidesScattertextLog.html'\n",
    "open(file_name, 'wb').write(html.encode('utf-8'))\n",
    "IFrame(src=file_name, width = 1200, height=700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Left  freq</th>\n",
       "      <th>Right  freq</th>\n",
       "      <th>Center  freq</th>\n",
       "      <th>left_precision</th>\n",
       "      <th>left_freq_pct</th>\n",
       "      <th>left_hmean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>65156</td>\n",
       "      <td>39152</td>\n",
       "      <td>32007</td>\n",
       "      <td>0.624650</td>\n",
       "      <td>0.029066</td>\n",
       "      <td>0.055548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>33333</td>\n",
       "      <td>19293</td>\n",
       "      <td>16035</td>\n",
       "      <td>0.633394</td>\n",
       "      <td>0.014870</td>\n",
       "      <td>0.029058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>27423</td>\n",
       "      <td>15101</td>\n",
       "      <td>12483</td>\n",
       "      <td>0.644883</td>\n",
       "      <td>0.012233</td>\n",
       "      <td>0.024011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>25512</td>\n",
       "      <td>13923</td>\n",
       "      <td>12429</td>\n",
       "      <td>0.646938</td>\n",
       "      <td>0.011381</td>\n",
       "      <td>0.022368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>25182</td>\n",
       "      <td>15096</td>\n",
       "      <td>11743</td>\n",
       "      <td>0.625205</td>\n",
       "      <td>0.011234</td>\n",
       "      <td>0.022071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>21704</td>\n",
       "      <td>11671</td>\n",
       "      <td>10671</td>\n",
       "      <td>0.650307</td>\n",
       "      <td>0.009682</td>\n",
       "      <td>0.019080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>that</th>\n",
       "      <td>17284</td>\n",
       "      <td>9158</td>\n",
       "      <td>7315</td>\n",
       "      <td>0.653657</td>\n",
       "      <td>0.007710</td>\n",
       "      <td>0.015241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trump</th>\n",
       "      <td>12010</td>\n",
       "      <td>6186</td>\n",
       "      <td>6223</td>\n",
       "      <td>0.660035</td>\n",
       "      <td>0.005358</td>\n",
       "      <td>0.010629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>on</th>\n",
       "      <td>11036</td>\n",
       "      <td>6049</td>\n",
       "      <td>6180</td>\n",
       "      <td>0.645947</td>\n",
       "      <td>0.004923</td>\n",
       "      <td>0.009772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>for</th>\n",
       "      <td>10334</td>\n",
       "      <td>6350</td>\n",
       "      <td>5359</td>\n",
       "      <td>0.619396</td>\n",
       "      <td>0.004610</td>\n",
       "      <td>0.009152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>’s</th>\n",
       "      <td>9679</td>\n",
       "      <td>5017</td>\n",
       "      <td>3281</td>\n",
       "      <td>0.658615</td>\n",
       "      <td>0.004318</td>\n",
       "      <td>0.008579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>he</th>\n",
       "      <td>9610</td>\n",
       "      <td>5063</td>\n",
       "      <td>4215</td>\n",
       "      <td>0.654944</td>\n",
       "      <td>0.004287</td>\n",
       "      <td>0.008518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is</th>\n",
       "      <td>9296</td>\n",
       "      <td>5758</td>\n",
       "      <td>4308</td>\n",
       "      <td>0.617510</td>\n",
       "      <td>0.004147</td>\n",
       "      <td>0.008239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it</th>\n",
       "      <td>8384</td>\n",
       "      <td>4698</td>\n",
       "      <td>3684</td>\n",
       "      <td>0.640881</td>\n",
       "      <td>0.003740</td>\n",
       "      <td>0.007437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>said</th>\n",
       "      <td>8196</td>\n",
       "      <td>4962</td>\n",
       "      <td>4738</td>\n",
       "      <td>0.622891</td>\n",
       "      <td>0.003656</td>\n",
       "      <td>0.007270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>with</th>\n",
       "      <td>7648</td>\n",
       "      <td>4457</td>\n",
       "      <td>3719</td>\n",
       "      <td>0.631805</td>\n",
       "      <td>0.003412</td>\n",
       "      <td>0.006787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>was</th>\n",
       "      <td>7593</td>\n",
       "      <td>4227</td>\n",
       "      <td>3423</td>\n",
       "      <td>0.642386</td>\n",
       "      <td>0.003387</td>\n",
       "      <td>0.006739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>his</th>\n",
       "      <td>7170</td>\n",
       "      <td>3394</td>\n",
       "      <td>3002</td>\n",
       "      <td>0.678720</td>\n",
       "      <td>0.003199</td>\n",
       "      <td>0.006367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>as</th>\n",
       "      <td>6923</td>\n",
       "      <td>3955</td>\n",
       "      <td>3223</td>\n",
       "      <td>0.636422</td>\n",
       "      <td>0.003088</td>\n",
       "      <td>0.006147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of the</th>\n",
       "      <td>6605</td>\n",
       "      <td>3593</td>\n",
       "      <td>2918</td>\n",
       "      <td>0.647676</td>\n",
       "      <td>0.002947</td>\n",
       "      <td>0.005866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'s</th>\n",
       "      <td>5591</td>\n",
       "      <td>3016</td>\n",
       "      <td>3823</td>\n",
       "      <td>0.649588</td>\n",
       "      <td>0.002494</td>\n",
       "      <td>0.004969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>not</th>\n",
       "      <td>5295</td>\n",
       "      <td>2943</td>\n",
       "      <td>2301</td>\n",
       "      <td>0.642753</td>\n",
       "      <td>0.002362</td>\n",
       "      <td>0.004707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>from</th>\n",
       "      <td>5096</td>\n",
       "      <td>2837</td>\n",
       "      <td>2430</td>\n",
       "      <td>0.642380</td>\n",
       "      <td>0.002273</td>\n",
       "      <td>0.004531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>have</th>\n",
       "      <td>5089</td>\n",
       "      <td>2838</td>\n",
       "      <td>2441</td>\n",
       "      <td>0.641983</td>\n",
       "      <td>0.002270</td>\n",
       "      <td>0.004524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>at</th>\n",
       "      <td>5083</td>\n",
       "      <td>2759</td>\n",
       "      <td>2553</td>\n",
       "      <td>0.648176</td>\n",
       "      <td>0.002268</td>\n",
       "      <td>0.004519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>by</th>\n",
       "      <td>4995</td>\n",
       "      <td>2889</td>\n",
       "      <td>2638</td>\n",
       "      <td>0.633562</td>\n",
       "      <td>0.002228</td>\n",
       "      <td>0.004441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>be</th>\n",
       "      <td>4929</td>\n",
       "      <td>3155</td>\n",
       "      <td>2564</td>\n",
       "      <td>0.609723</td>\n",
       "      <td>0.002199</td>\n",
       "      <td>0.004382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in the</th>\n",
       "      <td>4887</td>\n",
       "      <td>2904</td>\n",
       "      <td>2449</td>\n",
       "      <td>0.627262</td>\n",
       "      <td>0.002180</td>\n",
       "      <td>0.004345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has</th>\n",
       "      <td>4708</td>\n",
       "      <td>2655</td>\n",
       "      <td>2372</td>\n",
       "      <td>0.639413</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.004187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>but</th>\n",
       "      <td>4618</td>\n",
       "      <td>2564</td>\n",
       "      <td>1925</td>\n",
       "      <td>0.642996</td>\n",
       "      <td>0.002060</td>\n",
       "      <td>0.004107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>this</th>\n",
       "      <td>4508</td>\n",
       "      <td>2943</td>\n",
       "      <td>2115</td>\n",
       "      <td>0.605019</td>\n",
       "      <td>0.002011</td>\n",
       "      <td>0.004009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>4497</td>\n",
       "      <td>2516</td>\n",
       "      <td>1777</td>\n",
       "      <td>0.641238</td>\n",
       "      <td>0.002006</td>\n",
       "      <td>0.004000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>president</th>\n",
       "      <td>4368</td>\n",
       "      <td>2955</td>\n",
       "      <td>2605</td>\n",
       "      <td>0.596477</td>\n",
       "      <td>0.001949</td>\n",
       "      <td>0.003884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>an</th>\n",
       "      <td>4354</td>\n",
       "      <td>2309</td>\n",
       "      <td>1948</td>\n",
       "      <td>0.653459</td>\n",
       "      <td>0.001942</td>\n",
       "      <td>0.003873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>who</th>\n",
       "      <td>4139</td>\n",
       "      <td>2106</td>\n",
       "      <td>2002</td>\n",
       "      <td>0.662770</td>\n",
       "      <td>0.001846</td>\n",
       "      <td>0.003683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>are</th>\n",
       "      <td>4050</td>\n",
       "      <td>2611</td>\n",
       "      <td>1889</td>\n",
       "      <td>0.608017</td>\n",
       "      <td>0.001807</td>\n",
       "      <td>0.003603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>they</th>\n",
       "      <td>3895</td>\n",
       "      <td>2367</td>\n",
       "      <td>1655</td>\n",
       "      <td>0.622006</td>\n",
       "      <td>0.001738</td>\n",
       "      <td>0.003465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>would</th>\n",
       "      <td>3853</td>\n",
       "      <td>2103</td>\n",
       "      <td>1852</td>\n",
       "      <td>0.646911</td>\n",
       "      <td>0.001719</td>\n",
       "      <td>0.003429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>we</th>\n",
       "      <td>3853</td>\n",
       "      <td>2584</td>\n",
       "      <td>1750</td>\n",
       "      <td>0.598571</td>\n",
       "      <td>0.001719</td>\n",
       "      <td>0.003428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>about</th>\n",
       "      <td>3608</td>\n",
       "      <td>1724</td>\n",
       "      <td>1523</td>\n",
       "      <td>0.676669</td>\n",
       "      <td>0.001610</td>\n",
       "      <td>0.003211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>had</th>\n",
       "      <td>3337</td>\n",
       "      <td>1497</td>\n",
       "      <td>1476</td>\n",
       "      <td>0.690319</td>\n",
       "      <td>0.001489</td>\n",
       "      <td>0.002971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to the</th>\n",
       "      <td>3272</td>\n",
       "      <td>1949</td>\n",
       "      <td>1583</td>\n",
       "      <td>0.626700</td>\n",
       "      <td>0.001460</td>\n",
       "      <td>0.002913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>will</th>\n",
       "      <td>3123</td>\n",
       "      <td>2417</td>\n",
       "      <td>1739</td>\n",
       "      <td>0.563718</td>\n",
       "      <td>0.001393</td>\n",
       "      <td>0.002779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>more</th>\n",
       "      <td>2877</td>\n",
       "      <td>1453</td>\n",
       "      <td>1877</td>\n",
       "      <td>0.664434</td>\n",
       "      <td>0.001283</td>\n",
       "      <td>0.002562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clinton</th>\n",
       "      <td>2874</td>\n",
       "      <td>1358</td>\n",
       "      <td>808</td>\n",
       "      <td>0.679112</td>\n",
       "      <td>0.001282</td>\n",
       "      <td>0.002559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>house</th>\n",
       "      <td>2790</td>\n",
       "      <td>1679</td>\n",
       "      <td>1742</td>\n",
       "      <td>0.624301</td>\n",
       "      <td>0.001245</td>\n",
       "      <td>0.002484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>or</th>\n",
       "      <td>2720</td>\n",
       "      <td>1450</td>\n",
       "      <td>1360</td>\n",
       "      <td>0.652278</td>\n",
       "      <td>0.001213</td>\n",
       "      <td>0.002422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>were</th>\n",
       "      <td>2606</td>\n",
       "      <td>1459</td>\n",
       "      <td>1150</td>\n",
       "      <td>0.641082</td>\n",
       "      <td>0.001163</td>\n",
       "      <td>0.002321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>people</th>\n",
       "      <td>2600</td>\n",
       "      <td>1467</td>\n",
       "      <td>1153</td>\n",
       "      <td>0.639292</td>\n",
       "      <td>0.001160</td>\n",
       "      <td>0.002316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>their</th>\n",
       "      <td>2599</td>\n",
       "      <td>1606</td>\n",
       "      <td>1250</td>\n",
       "      <td>0.618074</td>\n",
       "      <td>0.001159</td>\n",
       "      <td>0.002315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Left  freq  Right  freq  Center  freq  left_precision  \\\n",
       "term                                                               \n",
       "the             65156        39152         32007        0.624650   \n",
       "to              33333        19293         16035        0.633394   \n",
       "of              27423        15101         12483        0.644883   \n",
       "a               25512        13923         12429        0.646938   \n",
       "and             25182        15096         11743        0.625205   \n",
       "in              21704        11671         10671        0.650307   \n",
       "that            17284         9158          7315        0.653657   \n",
       "trump           12010         6186          6223        0.660035   \n",
       "on              11036         6049          6180        0.645947   \n",
       "for             10334         6350          5359        0.619396   \n",
       "’s               9679         5017          3281        0.658615   \n",
       "he               9610         5063          4215        0.654944   \n",
       "is               9296         5758          4308        0.617510   \n",
       "it               8384         4698          3684        0.640881   \n",
       "said             8196         4962          4738        0.622891   \n",
       "with             7648         4457          3719        0.631805   \n",
       "was              7593         4227          3423        0.642386   \n",
       "his              7170         3394          3002        0.678720   \n",
       "as               6923         3955          3223        0.636422   \n",
       "of the           6605         3593          2918        0.647676   \n",
       "'s               5591         3016          3823        0.649588   \n",
       "not              5295         2943          2301        0.642753   \n",
       "from             5096         2837          2430        0.642380   \n",
       "have             5089         2838          2441        0.641983   \n",
       "at               5083         2759          2553        0.648176   \n",
       "by               4995         2889          2638        0.633562   \n",
       "be               4929         3155          2564        0.609723   \n",
       "in the           4887         2904          2449        0.627262   \n",
       "has              4708         2655          2372        0.639413   \n",
       "but              4618         2564          1925        0.642996   \n",
       "this             4508         2943          2115        0.605019   \n",
       "i                4497         2516          1777        0.641238   \n",
       "president        4368         2955          2605        0.596477   \n",
       "an               4354         2309          1948        0.653459   \n",
       "who              4139         2106          2002        0.662770   \n",
       "are              4050         2611          1889        0.608017   \n",
       "they             3895         2367          1655        0.622006   \n",
       "would            3853         2103          1852        0.646911   \n",
       "we               3853         2584          1750        0.598571   \n",
       "about            3608         1724          1523        0.676669   \n",
       "had              3337         1497          1476        0.690319   \n",
       "to the           3272         1949          1583        0.626700   \n",
       "will             3123         2417          1739        0.563718   \n",
       "more             2877         1453          1877        0.664434   \n",
       "clinton          2874         1358           808        0.679112   \n",
       "house            2790         1679          1742        0.624301   \n",
       "or               2720         1450          1360        0.652278   \n",
       "were             2606         1459          1150        0.641082   \n",
       "people           2600         1467          1153        0.639292   \n",
       "their            2599         1606          1250        0.618074   \n",
       "\n",
       "           left_freq_pct  left_hmean  \n",
       "term                                  \n",
       "the             0.029066    0.055548  \n",
       "to              0.014870    0.029058  \n",
       "of              0.012233    0.024011  \n",
       "a               0.011381    0.022368  \n",
       "and             0.011234    0.022071  \n",
       "in              0.009682    0.019080  \n",
       "that            0.007710    0.015241  \n",
       "trump           0.005358    0.010629  \n",
       "on              0.004923    0.009772  \n",
       "for             0.004610    0.009152  \n",
       "’s              0.004318    0.008579  \n",
       "he              0.004287    0.008518  \n",
       "is              0.004147    0.008239  \n",
       "it              0.003740    0.007437  \n",
       "said            0.003656    0.007270  \n",
       "with            0.003412    0.006787  \n",
       "was             0.003387    0.006739  \n",
       "his             0.003199    0.006367  \n",
       "as              0.003088    0.006147  \n",
       "of the          0.002947    0.005866  \n",
       "'s              0.002494    0.004969  \n",
       "not             0.002362    0.004707  \n",
       "from            0.002273    0.004531  \n",
       "have            0.002270    0.004524  \n",
       "at              0.002268    0.004519  \n",
       "by              0.002228    0.004441  \n",
       "be              0.002199    0.004382  \n",
       "in the          0.002180    0.004345  \n",
       "has             0.002100    0.004187  \n",
       "but             0.002060    0.004107  \n",
       "this            0.002011    0.004009  \n",
       "i               0.002006    0.004000  \n",
       "president       0.001949    0.003884  \n",
       "an              0.001942    0.003873  \n",
       "who             0.001846    0.003683  \n",
       "are             0.001807    0.003603  \n",
       "they            0.001738    0.003465  \n",
       "would           0.001719    0.003429  \n",
       "we              0.001719    0.003428  \n",
       "about           0.001610    0.003211  \n",
       "had             0.001489    0.002971  \n",
       "to the          0.001460    0.002913  \n",
       "will            0.001393    0.002779  \n",
       "more            0.001283    0.002562  \n",
       "clinton         0.001282    0.002559  \n",
       "house           0.001245    0.002484  \n",
       "or              0.001213    0.002422  \n",
       "were            0.001163    0.002321  \n",
       "people          0.001160    0.002316  \n",
       "their           0.001159    0.002315  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_freq_df = corpus.get_term_freq_df()\n",
    "term_freq_df['left_precision'] = term_freq_df['Left  freq'] * 1./(term_freq_df['Left  freq'] + term_freq_df['Right  freq'])\n",
    "term_freq_df['left_freq_pct'] = term_freq_df['Left  freq'] * 1./term_freq_df['Left  freq'].sum()\n",
    "term_freq_df['left_hmean'] = term_freq_df.apply(lambda x: (hmean([x['left_precision'], x['left_freq_pct']])\n",
    "                                                                   if x['left_precision'] > 0 and x['left_freq_pct'] > 0 \n",
    "                                                                   else 0), axis=1)                                                        \n",
    "term_freq_df.sort_values(by='left_hmean', ascending=False).iloc[:50]                                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/meldye/anaconda/envs/newscrawl/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Users/meldye/anaconda/envs/newscrawl/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Users/meldye/anaconda/envs/newscrawl/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1738: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  cond2 = (x >= self.b) & cond0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Left  freq</th>\n",
       "      <th>Right  freq</th>\n",
       "      <th>Center  freq</th>\n",
       "      <th>left_precision</th>\n",
       "      <th>left_freq_pct</th>\n",
       "      <th>left_hmean</th>\n",
       "      <th>left_precision_normcdf</th>\n",
       "      <th>left_freq_pct_normcdf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>david becker</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.461028e-07</td>\n",
       "      <td>8.922051e-07</td>\n",
       "      <td>0.805784</td>\n",
       "      <td>0.492209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>different policies</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.461028e-07</td>\n",
       "      <td>8.922051e-07</td>\n",
       "      <td>0.805784</td>\n",
       "      <td>0.492209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>presidents nicolas</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.461028e-07</td>\n",
       "      <td>8.922051e-07</td>\n",
       "      <td>0.805784</td>\n",
       "      <td>0.492209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sarkozy and</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.461028e-07</td>\n",
       "      <td>8.922051e-07</td>\n",
       "      <td>0.805784</td>\n",
       "      <td>0.492209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and françois</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.461028e-07</td>\n",
       "      <td>8.922051e-07</td>\n",
       "      <td>0.805784</td>\n",
       "      <td>0.492209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hollande very</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.461028e-07</td>\n",
       "      <td>8.922051e-07</td>\n",
       "      <td>0.805784</td>\n",
       "      <td>0.492209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>different orientations</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.461028e-07</td>\n",
       "      <td>8.922051e-07</td>\n",
       "      <td>0.805784</td>\n",
       "      <td>0.492209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>orientations very</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.461028e-07</td>\n",
       "      <td>8.922051e-07</td>\n",
       "      <td>0.805784</td>\n",
       "      <td>0.492209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>still we</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.461028e-07</td>\n",
       "      <td>8.922051e-07</td>\n",
       "      <td>0.805784</td>\n",
       "      <td>0.492209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>two consecutive</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.461028e-07</td>\n",
       "      <td>8.922051e-07</td>\n",
       "      <td>0.805784</td>\n",
       "      <td>0.492209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Left  freq  Right  freq  Center  freq  left_precision  \\\n",
       "term                                                                            \n",
       "david becker                     1            0             0             1.0   \n",
       "different policies               1            0             0             1.0   \n",
       "presidents nicolas               1            0             0             1.0   \n",
       "sarkozy and                      1            0             0             1.0   \n",
       "and françois                     1            0             0             1.0   \n",
       "hollande very                    1            0             0             1.0   \n",
       "different orientations           1            0             0             1.0   \n",
       "orientations very                1            0             0             1.0   \n",
       "still we                         1            0             0             1.0   \n",
       "two consecutive                  1            0             0             1.0   \n",
       "\n",
       "                        left_freq_pct    left_hmean  left_precision_normcdf  \\\n",
       "term                                                                          \n",
       "david becker             4.461028e-07  8.922051e-07                0.805784   \n",
       "different policies       4.461028e-07  8.922051e-07                0.805784   \n",
       "presidents nicolas       4.461028e-07  8.922051e-07                0.805784   \n",
       "sarkozy and              4.461028e-07  8.922051e-07                0.805784   \n",
       "and françois             4.461028e-07  8.922051e-07                0.805784   \n",
       "hollande very            4.461028e-07  8.922051e-07                0.805784   \n",
       "different orientations   4.461028e-07  8.922051e-07                0.805784   \n",
       "orientations very        4.461028e-07  8.922051e-07                0.805784   \n",
       "still we                 4.461028e-07  8.922051e-07                0.805784   \n",
       "two consecutive          4.461028e-07  8.922051e-07                0.805784   \n",
       "\n",
       "                        left_freq_pct_normcdf  \n",
       "term                                           \n",
       "david becker                         0.492209  \n",
       "different policies                   0.492209  \n",
       "presidents nicolas                   0.492209  \n",
       "sarkozy and                          0.492209  \n",
       "and françois                         0.492209  \n",
       "hollande very                        0.492209  \n",
       "different orientations               0.492209  \n",
       "orientations very                    0.492209  \n",
       "still we                             0.492209  \n",
       "two consecutive                      0.492209  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def normcdf(x):\n",
    "    return norm.cdf(x, x.mean(), x.std())\n",
    "term_freq_df['left_precision_normcdf'] = normcdf(term_freq_df['left_precision'])\n",
    "term_freq_df['left_freq_pct_normcdf'] = normcdf(term_freq_df['left_freq_pct'])\n",
    "\n",
    "\n",
    "\n",
    "#term_freq_df['left_scaled_f_score'] = hmean([term_freq_df['left_precision_normcdf'], term_freq_df['left_freq_pct_normcdf']])\n",
    "term_freq_df.sort_values(by='left_precision_normcdf', ascending=False).iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'left_precision_normcdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda/envs/newscrawl/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3062\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3063\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3064\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'left_precision_normcdf'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-2e819b57c34d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mterm_freq_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'left_precision_normcdf'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda/envs/newscrawl/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2683\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2684\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2685\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2687\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/newscrawl/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2690\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2691\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2692\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2694\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/newscrawl/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   2484\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2485\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2486\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2487\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2488\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/newscrawl/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   4113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4114\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4115\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4116\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4117\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/newscrawl/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3063\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3064\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3065\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3066\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3067\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'left_precision_normcdf'"
     ]
    }
   ],
   "source": [
    "term_freq_df['left_precision_normcdf']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
