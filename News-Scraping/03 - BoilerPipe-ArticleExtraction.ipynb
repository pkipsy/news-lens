{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BoilerPipe for Article Extraction\n",
    "\n",
    "[BoilerPipe](https://boilerpipe-web.appspot.com/) is a project of Kohlsch√ºtter Search Intelligence. BoilerPipe \"provides algorithms to detect and remove the surplus \"clutter\" (boilerplate, templates) around the main textual content of a web page.\" In short, it's great for parsing news articles.\n",
    "\n",
    "While there are [python wrappers](https://github.com/misja/python-boilerpipe) for BoilerPipe, here we are making use of its Web API, which returns better-cleaned .json.\n",
    "\n",
    "Note: Because of BoilerPipe's strict rate limits, [NewsPlease](https://github.com/fhamborg/news-please) is the preferred alternative when batch processing at scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import urllib.request\n",
    "import urllib.error\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from itertools import cycle\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we load links harvested with our All Sides Media spider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load news links harvested from spider\n",
    "with open('link_file.txt') as f:\n",
    "    news_links = [line for line in f]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To successfully query BoilerPipe's Web API, we need to make some minor changes to the link format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_links = []\n",
    "\n",
    "# reformat links to successfully query BoilerPipe's web API\n",
    "def reformat_links(news_links):\n",
    "    for link in news_links:\n",
    "        new_link = link.replace(':', '%3A')\n",
    "        new_link = new_link.replace('/','%2F')\n",
    "        \n",
    "        link_start = 'https://boilerpipe-web.appspot.com/extract?url='\n",
    "        link_end = '&extractor=ArticleExtractor&output=json&extractImages=&token='\n",
    "        new_link = link_start + new_link + link_end\n",
    "        \n",
    "        clean_link = new_link.replace(\"\\n\", \"\")\n",
    "        \n",
    "        updated_links.append(clean_link)\n",
    "\n",
    "reformat_links(news_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now set about iterating through our list of links, and parsing the news articles through BoilerPip's Web API. The article content will be returned to us in .json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query BoilerPipe's web API, retrieving and storing json summaries\n",
    "article_collection = []\n",
    "def scrape_page(updated_links):\n",
    "    for url_query in updated_links:\n",
    "        try:\n",
    "            page = urllib.request.urlopen(url_query)\n",
    "            time.sleep(5)\n",
    "            article_collection.append(page)\n",
    "        except HTTPError:\n",
    "            article_collection.append('Pay Wall')\n",
    "\n",
    "scrape_page(updated_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read information to json\n",
    "import json\n",
    "with open('newsarticle-texts.txt', 'w') as outfile:\n",
    "    json.dump(article_collection, outfile, ensure_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
